{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, make_scorer, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras import backend as k\n",
    "import math\n",
    "from keras.utils import to_categorical   \n",
    "\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d',\n",
      "       'word_freq_our', 'word_freq_over', 'word_freq_remove',\n",
      "       'word_freq_internet', 'word_freq_order', 'word_freq_mail',\n",
      "       'word_freq_receive', 'word_freq_will', 'word_freq_people',\n",
      "       'word_freq_report', 'word_freq_addresses', 'word_freq_free',\n",
      "       'word_freq_business', 'word_freq_email', 'word_freq_you',\n",
      "       'word_freq_credit', 'word_freq_your', 'word_freq_font', 'word_freq_000',\n",
      "       'word_freq_money', 'word_freq_hp', 'word_freq_hpl', 'word_freq_george',\n",
      "       'word_freq_650', 'word_freq_lab', 'word_freq_labs', 'word_freq_telnet',\n",
      "       'word_freq_857', 'word_freq_data', 'word_freq_415', 'word_freq_85',\n",
      "       'word_freq_technology', 'word_freq_1999', 'word_freq_parts',\n",
      "       'word_freq_pm', 'word_freq_direct', 'word_freq_cs', 'word_freq_meeting',\n",
      "       'word_freq_original', 'word_freq_project', 'word_freq_re',\n",
      "       'word_freq_edu', 'word_freq_table', 'word_freq_conference',\n",
      "       'char_freq_1', 'char_freq_2', 'char_freq_3', 'char_freq_4',\n",
      "       'char_freq_5', 'char_freq_6', 'capital_run_length_average',\n",
      "       'capital_run_length_longest', 'capital_run_length_total', 'flag'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_1</th>\n",
       "      <th>char_freq_2</th>\n",
       "      <th>char_freq_3</th>\n",
       "      <th>char_freq_4</th>\n",
       "      <th>char_freq_5</th>\n",
       "      <th>char_freq_6</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  char_freq_1  char_freq_2  \\\n",
       "0             0.00            0.00  ...         0.00        0.000   \n",
       "1             0.00            0.94  ...         0.00        0.132   \n",
       "2             0.64            0.25  ...         0.01        0.143   \n",
       "3             0.31            0.63  ...         0.00        0.137   \n",
       "4             0.31            0.63  ...         0.00        0.135   \n",
       "\n",
       "   char_freq_3  char_freq_4  char_freq_5  char_freq_6  \\\n",
       "0          0.0        0.778        0.000        0.000   \n",
       "1          0.0        0.372        0.180        0.048   \n",
       "2          0.0        0.276        0.184        0.010   \n",
       "3          0.0        0.137        0.000        0.000   \n",
       "4          0.0        0.135        0.000        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  flag  \n",
       "0                       278     1  \n",
       "1                      1028     1  \n",
       "2                      2259     1  \n",
       "3                       191     1  \n",
       "4                       191     1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [    'word_freq_make',      'word_freq_address',   'word_freq_all',       'word_freq_3d',        'word_freq_our',       'word_freq_over',  'word_freq_remove',    \n",
    "            'word_freq_internet',  'word_freq_order',     'word_freq_mail',      'word_freq_receive',   'word_freq_will',      'word_freq_people',    \n",
    "            'word_freq_report',    'word_freq_addresses', 'word_freq_free',      'word_freq_business',  'word_freq_email',     'word_freq_you', \n",
    "            'word_freq_credit',    'word_freq_your',      'word_freq_font',      'word_freq_000',       'word_freq_money',     'word_freq_hp',        \n",
    "            'word_freq_hpl',       'word_freq_george',    'word_freq_650',       'word_freq_lab',       'word_freq_labs',      'word_freq_telnet',    \n",
    "            'word_freq_857',       'word_freq_data',      'word_freq_415',       'word_freq_85',        'word_freq_technology','word_freq_1999',      \n",
    "            'word_freq_parts',     'word_freq_pm',        'word_freq_direct',    'word_freq_cs',        'word_freq_meeting',   'word_freq_original',  \n",
    "            'word_freq_project',   'word_freq_re',        'word_freq_edu',       'word_freq_table',     'word_freq_conference','char_freq_1',            \n",
    "            'char_freq_2',         'char_freq_3',         'char_freq_4',         'char_freq_5',         'char_freq_6',         'capital_run_length_average',\n",
    "            'capital_run_length_longest',                 'capital_run_length_total' ,                  'flag']\n",
    "\n",
    "data = pd.read_csv('spambase.data', names = cols)\n",
    "print(data.columns)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the Data Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flag\n",
       "0    2788\n",
       "1    1813\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('flag').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_wt = {0:2788, 1:1813}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,:57]\n",
    "Y = data.iloc[:,57:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We Check for correlations between variables to find and eliminate variables which are highly correlated with each other.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix = X.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word_freq_857', 'word_freq_415', 'word_freq_technology', 'word_freq_direct']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find features with correlation greater than 0.65\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.65)]\n",
    "to_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization and Train test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop features \n",
    "new_features = X.drop(to_drop, axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.20,random_state=45)\n",
    "\n",
    "## Data Normalization\n",
    "x_train = MinMaxScaler().fit_transform(x_train)\n",
    "x_test  = MinMaxScaler().fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Standard Scaler provides negative values, It cannot be used as Naive Bayes cannot hav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to Classify the variables using the following models:\n",
    "1. Logistic Regression  \n",
    "2. SVM  \n",
    "3. Decision Trees \n",
    "4. K Nearest Neighbors  \n",
    "5. Naiive Bayes Calssifier  \n",
    "6. Neural networks  \n",
    "7. Random Forest  \n",
    "8. XgBoost  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We First Run A Nested GridSearch Between 5 Traditional models. We need to manually tune Random Forest, Neural network and XGBoost to get he best accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested GridSearch To Select the best Possible Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: nb\n",
      "Training: svm\n",
      "Training: dt\n",
      "Training: logit\n",
      "Training: knn\n",
      "[0.88994565 0.92961957 0.91603261 0.88858696 0.91222826 0.\n",
      " 0.        ]\n",
      "204.78466153144836\n"
     ]
    }
   ],
   "source": [
    "a = time.time()\n",
    "non_nested_scores = np.zeros(7)\n",
    "nested_scores = np.zeros(7)\n",
    "\n",
    "# Setting up Classifiers and parameter dictionaries\n",
    "svm = SVC(class_weight=class_wt, random_state= 42)\n",
    "svm_params = [{'kernel': ['rbf'], 'gamma': [1e-2, 1e-3, 1e-4],'C': np.arange(0.01,3,0.5)},\n",
    "              {'kernel': ['linear'], 'C': np.arange(0.01,3,0.5)}\n",
    "              {'kernel': ['poly'], 'C': np.arange(0.01,3,0.5), 'degree': np.arange(1, 6, 1), 'coef0':np.arange(0,3,0.5)},\n",
    "              {'kernel':['sigmoid'], 'gamma': [1e-2, 1e-3, 1e-4], 'C': np.arange(0.01,3,0.5)}\n",
    "             ]\n",
    "\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state = 10, class_weight=class_wt)\n",
    "dt_grid = {'max_depth':list(range(1,15)), \n",
    "           'criterion':['gini', 'entropy'],\n",
    "           'splitter':['best', 'random'],\n",
    "           'min_weight_fraction_leaf':[i/10 for i in range(6)],\n",
    "           'max_features':list(range(1, 57)),\n",
    "           'min_impurity_decrease':np.arange(0.0001, 0.005, 0.0005),\n",
    "           'min_samples_split':list(range(2,15)), \n",
    "           'min_samples_leaf':list(range(2,15)),\n",
    "          }\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn_grid = {'n_neighbors':list(range(1,20)), \n",
    "            'weights':['uniform', 'distance'], \n",
    "            'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "            'p':[1,2]}\n",
    "\n",
    "logit = LogisticRegression(random_state=10, multi_class= 'multinomial', solver='saga', class_weight = class_wt)\n",
    "lt_grid = {'penalty':['l1','l2'], 'C':list(np.arange(1, 10, 1))}\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb_grid = [{'alpha': np.arange(1,10,0.5)}]\n",
    "\n",
    "classifiers = [nb, svm, dt,logit, knn]\n",
    "classifiers_p = ['nb','svm', 'dt','logit', 'knn']\n",
    "dicts = [nb_grid, svm_params, dt_grid, lt_grid, knn_grid]\n",
    "\n",
    "\n",
    "# Nested cross-validation\n",
    "for i in range(5):\n",
    "    print('Training:' , classifiers_p[i])\n",
    "    inner_cv = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "    outer_cv = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "    # Non_nested parameter search and scoring\n",
    "    clf = GridSearchCV(estimator=classifiers[i], param_grid=dicts[i], cv=inner_cv, iid=False, n_jobs = -1, scoring= 'accuracy', verbose = 0)\n",
    "    clf.fit(x_train, y_train)\n",
    "    non_nested_scores[i] = clf.best_score_\n",
    "\n",
    "    # Nested CV with parameter optimization\n",
    "    nested_score = cross_val_score(clf, X=x_train, y=y_train, cv=outer_cv)\n",
    "    nested_scores[i] = nested_score.mean()\n",
    "    \n",
    "print(nested_scores)\n",
    "print(time.time() - a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From nested Gridsearch, SVM Provides the best accuracy for the model.  \n",
    "We perform further Hyperparameter Tunig to get the best parameters for SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   17.8s\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(class_weight=class_wt, random_state= 42)\n",
    "svm_params = [{'kernel': ['rbf'], 'gamma': [1e-2, 1e-3, 1e-4],'C': np.arange(0.01,3,0.5)},\n",
    "              {'kernel': ['linear'], 'C': np.arange(0.01,3,0.5)},\n",
    "#               {'kernel': ['poly'], 'C': np.arange(0.01,3,0.5), 'degree': np.arange(1, 3, 1), 'coef0':np.arange(0,3,0.5)},\n",
    "              {'kernel':['sigmoid'], 'gamma': [1e-2, 1e-3, 1e-4], 'C': np.arange(0.01,3,0.5)}\n",
    "             ]\n",
    "\n",
    "classifier = GridSearchCV(svm, param_grid= svm_params, cv = 5, scoring = \"accuracy\", n_jobs = -1, verbose = 1)\n",
    "classifier.fit(x_train, y_train)\n",
    "print(\"Best Score:\",classifier.best_score_)\n",
    "print(\"Best Parameters:\",classifier.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.923\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(class_weight=class_wt, C = 2.51, gamma = 0.01, kernel = 'rbf')\n",
    "svm.fit(x_train, y_train)\n",
    "\n",
    "print('SVM Accuracy:',accuracy(y_test, svm.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting Target Variable to Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train1 = to_categorical(y_train, num_classes=2)\n",
    "y_test1 = to_categorical(y_test, num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Basic Neural Network is used to Train the model. We use 3 hidden layers and an output layer to predict if an observation will be classified as a 1 or a zero.  \n",
    "Further, We use sigmoid as output function and categorical crossentropy to calculate the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train: 0.20105220643074617 loss_test: 0.22966289782368787\n",
      "accuracy_train: 0.92744565 accuracy_test: 0.91856676\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(units = 57, activation = tf.nn.leaky_relu , input_shape=(57,)),\n",
    "        tf.keras.layers.Dense(units = 16, activation = tf.nn.leaky_relu),\n",
    "        tf.keras.layers.Dense(units = 16, activation = tf.nn.leaky_relu),\n",
    "        tf.keras.layers.Dense(units = 16, activation = tf.nn.leaky_relu),\n",
    "        tf.keras.layers.Dense(2, activation=\"sigmoid\")])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "clf = model.fit(pd.DataFrame(x_train),\n",
    "                pd.DataFrame(y_train1),\n",
    "                batch_size= 10, epochs = 50, verbose = 0, validation_split= 0.2)\n",
    "\n",
    "loss_train, accuracy_train = model.evaluate(x_train, y_train1, verbose = False)\n",
    "loss, accuracy = model.evaluate(x_test, y_test1, verbose = False)\n",
    "print('loss_train:', loss_train, 'loss_test:', loss)\n",
    "print('accuracy_train:', accuracy_train, 'accuracy_test:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe an accuracy of 92% with Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   21.6s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   38.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   50.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 195, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_depth': 18, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(bootstrap=True, random_state= False, class_weight=class_wt)\n",
    "rf_grid = {\n",
    "    'n_estimators':range(5,200,10),\n",
    "    'criterion':['gini', 'entropy'],\n",
    "    'max_depth':range(3,20),\n",
    "    'min_samples_split':list(range(2,15)), \n",
    "    'min_samples_leaf':list(range(2,15))\n",
    "    }\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=rf_grid, n_iter=200, scoring='accuracy', \n",
    "                              cv=KFold(n_splits=5, shuffle=True, random_state=45), verbose=1, n_jobs=-1, random_state=45)\n",
    "rf_random.fit(x_train, y_train)\n",
    "print(rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9294462293607918\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators =195, min_samples_split=10, min_samples_leaf = 2, max_depth= 18, criterion ='entropy')\n",
    "print('Accuracy:',accuracy(y_test, rf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Baseline Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.8, 'reg_alpha': 0.1, 'n_estimators': 175, 'min_child_weight': 1, 'max_depth': 13, 'learning_rate': 0.1, 'gamma': 0.4, 'colsample_bytree': 0.8}\n"
     ]
    }
   ],
   "source": [
    "xg=xgb.XGBClassifier(random_state = 42)\n",
    "xg_grid = {\n",
    "    'learning_rate':[0.1,0.05,0.01],\n",
    "    'n_estimators':range(5,200,10),\n",
    "    'max_depth':range(3,20),\n",
    "    'min_child_weight':range(1,6),\n",
    "    'gamma':[i/10.0 for i in range(0,5)],\n",
    "    'subsample':[i/10.0 for i in range(6,10)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,10)],\n",
    "    'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "    }\n",
    "\n",
    "xg_random = RandomizedSearchCV(estimator=xg, param_distributions=xg_grid,  n_iter=500, scoring='accuracy', \n",
    "                              cv=KFold(n_splits=4, shuffle=True, random_state=45), verbose=0, n_jobs=-1, random_state=45)\n",
    "\n",
    "xg_random.fit(x_train, y_train)\n",
    "print(xg_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.931610731525294\n"
     ]
    }
   ],
   "source": [
    "xg = xgb.XGBClassifier(subsample = 0.8, \n",
    "                       reg_alpha= 0.1, \n",
    "                       n_estimators= 175, \n",
    "                       min_child_weight=1, \n",
    "                       max_depth = 13, \n",
    "                       learning_rate = 0.1, \n",
    "                       gamma =0.4, \n",
    "                       colsample_bytree =0.8)\n",
    "print('SVM Accuracy:',accuracy(y_test, xg.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Above Parameters, We first Train the Model for Max Depth and Child Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.95625\n",
      "Best parameters: {'max_depth': 24, 'min_child_weight': 1}\n"
     ]
    }
   ],
   "source": [
    "# Grid Search for best parameters\n",
    "param_test = {'max_depth':list(range(10,25,2)), \n",
    "              'min_child_weight':list(range(1,8,2))}\n",
    "\n",
    "gsearch=GridSearchCV(estimator=xgb.XGBClassifier(subsample = 0.8, \n",
    "                                               reg_alpha= 0.1, \n",
    "                                               n_estimators= 175,\n",
    "                                               learning_rate = 0.1, \n",
    "                                               gamma =0.4, \n",
    "                                               colsample_bytree =0.8,\n",
    "                                                njobs=-1,\n",
    "                                                scale_pos_weight=1,\n",
    "                                                seed=123),\n",
    "                      param_grid=param_test,\n",
    "                      scoring='accuracy',\n",
    "                      n_jobs=-1,\n",
    "                      iid=True,\n",
    "                      cv=5, verbose=0)\n",
    "\n",
    "gsearch.fit(x_train, y_train)\n",
    "print(\"Best Score:\",gsearch.best_score_)\n",
    "print(\"Best parameters:\",gsearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We Then Use this to Set Learning Rate and number of estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.9567934782608696\n",
      "Best parameters: {'learning_rate': 0.15000000000000002, 'n_estimators': 190}\n"
     ]
    }
   ],
   "source": [
    "# Grid Search for best parameters\n",
    "param_test = {'learning_rate':list(np.arange(0.05,1,0.05)), \n",
    "              'n_estimators':list(range(100,225,10))}\n",
    "\n",
    "gsearch=GridSearchCV(estimator=xgb.XGBClassifier(learning_rate=0.15,\n",
    "                                                n_estimators=100,\n",
    "                                                max_depth=24,\n",
    "                                                min_child_weight=1,\n",
    "                                                gamma=0,\n",
    "                                                subsample=0.9,\n",
    "                                                colsample_bytree=0.8,\n",
    "                                                njobs=-1,\n",
    "                                                scale_pos_weight=1,\n",
    "                                                seed=123),\n",
    "                      param_grid=param_test,\n",
    "                      scoring='accuracy',\n",
    "                      n_jobs=-1,\n",
    "                      iid=True,\n",
    "                      cv=5, verbose=0)\n",
    "\n",
    "gsearch.fit(x_train, y_train)\n",
    "print(\"Best Score:\",gsearch.best_score_)\n",
    "print(\"Best parameters:\",gsearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We use above obtained Results for Regularization Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  20 | elapsed:    9.8s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   10.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.9567934782608696\n",
      "Best parameters: {'reg_lambda': 1}\n"
     ]
    }
   ],
   "source": [
    "# Grid Search for best parameters\n",
    "param_test = {'reg_lambda':[0.1, 0.5,1,2]}\n",
    "\n",
    "gsearch=GridSearchCV(estimator=xgb.XGBClassifier(learning_rate=0.15,\n",
    "                                                n_estimators=190,\n",
    "                                                max_depth=24,\n",
    "                                                min_child_weight=1,\n",
    "                                                gamma=0,\n",
    "                                                subsample=0.9,\n",
    "                                                colsample_bytree=0.8,\n",
    "                                                njobs=-1,\n",
    "                                                scale_pos_weight=1,\n",
    "                                                seed=123),\n",
    "                      param_grid=param_test,\n",
    "                      scoring='accuracy',\n",
    "                      n_jobs=-1,\n",
    "                      iid=True,\n",
    "                      cv=5, verbose=1)\n",
    "\n",
    "gsearch.fit(x_train, y_train)\n",
    "print(\"Best Score:\",gsearch.best_score_)\n",
    "print(\"Best parameters:\",gsearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then We use the Learning Rate and estimatiors to again get best max_depth and child weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.9567934782608696\n",
      "Best parameters: {'max_depth': 24, 'min_child_weight': 1}\n"
     ]
    }
   ],
   "source": [
    "# Grid Search for best parameters\n",
    "param_test = {'max_depth':list(range(10,25,2)), \n",
    "              'min_child_weight':list(range(1,8,2))}\n",
    "\n",
    "gsearch=GridSearchCV(estimator=xgb.XGBClassifier(learning_rate=0.15,\n",
    "                                                n_estimators=190,\n",
    "                                                gamma=0,\n",
    "                                                subsample=0.9,\n",
    "                                                colsample_bytree=0.8,\n",
    "                                                njobs=-1,\n",
    "                                                scale_pos_weight=1,\n",
    "                                                seed=123,\n",
    "                                                reg_lambda = 1),\n",
    "                      param_grid=param_test,\n",
    "                      scoring='accuracy',\n",
    "                      n_jobs=-1,\n",
    "                      iid=True,\n",
    "                      cv=5, verbose=1)\n",
    "\n",
    "gsearch.fit(x_train, y_train)\n",
    "print(\"Best Score:\",gsearch.best_score_)\n",
    "print(\"Best parameters:\",gsearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.9348534201954397\n"
     ]
    }
   ],
   "source": [
    "xg = xgb.XGBClassifier(learning_rate=0.15,\n",
    "                        n_estimators=150,\n",
    "                        max_depth=24,\n",
    "                        min_child_weight=1,\n",
    "                        gamma=0,\n",
    "                        subsample=0.9,\n",
    "                        colsample_bytree=0.8,\n",
    "                        njobs=-1,\n",
    "                        scale_pos_weight=1,\n",
    "                        seed=123,\n",
    "                        reg_lambda = 1)\n",
    "xg.fit(x_train, y_train)\n",
    "print(\"accuracy_score:\", accuracy_score(y_test, xg.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Classifier | Accuracy |\n",
    "|--|--|\n",
    "|SVM|92.3|\n",
    "|Neural Network|91.8|\n",
    "|Random Forest|92.9|\n",
    "|XGBoost|93.5|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Defining Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We Define the cost function as Follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_cost_function(y_true, y_pred):\n",
    "    fp = confusion_matrix(y_pred, y_true) [1,0]\n",
    "    fl = confusion_matrix(y_pred, y_true) [0,1]\n",
    "    \n",
    "    c = (-10 *fp) - fl\n",
    "    return c\n",
    "scr = make_scorer(custom_cost_function, greater_is_better = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We Assume that in a classification problem, Classifying a correct email as a spam is much more dangerous than classifying incorrect email as not spam.\n",
    "\n",
    "If a correct mail is classified as SPAM, it may lead to a great deal of loss for the user as an important piece of imformation is lost. On the contrary, If a spam ends up in the inbox of a user, it may not be such a big deal. It is inconvenient, but the cost of this misclassification is much lower.\n",
    "\n",
    "because of this We Define the cost as follows:  \n",
    "False Positive: 10  \n",
    "False Negative: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We First Run A Nested GridSearch Between 5 Traditional models. We need to manually tune Random Forest, Neural network and XGBoost to get he best accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested GridSearch To Select the best Possible Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: svm\n",
      "Training: dt\n",
      "Training: logit\n",
      "Training: knn\n",
      "[-238.   -263.5  -429.   -303.75]\n"
     ]
    }
   ],
   "source": [
    "non_nested_scores = np.zeros(4)\n",
    "nested_scores = np.zeros(4)\n",
    "\n",
    "# Setting up Classifiers and parameter dictionaries\n",
    "svm = SVC(class_weight=class_wt, random_state= 42)\n",
    "svm_params = [{'kernel': ['rbf'], 'gamma': [1e-2, 1e-3, 1e-4],'C': np.arange(0.01,3,0.5)},\n",
    "              {'kernel': ['linear'], 'C': np.arange(0.01,3,0.5)}\n",
    "              {'kernel': ['poly'], 'C': np.arange(0.01,3,0.5), 'degree': np.arange(1, 6, 1), 'coef0':np.arange(0,3,0.5)},\n",
    "              {'kernel':['sigmoid'], 'gamma': [1e-2, 1e-3, 1e-4], 'C': np.arange(0.01,3,0.5)}\n",
    "             ]\n",
    "\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state = 10, class_weight=class_wt)\n",
    "dt_grid = {'max_depth':list(range(1,15)), \n",
    "           'criterion':['gini', 'entropy'],\n",
    "           'splitter':['best', 'random'],\n",
    "           'min_weight_fraction_leaf':[i/10 for i in range(6)],\n",
    "           'max_features':list(range(1, 57)),\n",
    "           'min_impurity_decrease':np.arange(0.0001, 0.005, 0.0005),\n",
    "           'min_samples_split':list(range(2,15)), \n",
    "           'min_samples_leaf':list(range(2,15)),\n",
    "          }\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn_grid = {'n_neighbors':list(range(1,10)), \n",
    "            'weights':['uniform', 'distance'], \n",
    "            'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "            'p':[1,2]\n",
    "           }\n",
    "\n",
    "logit = LogisticRegression(random_state=10, multi_class= 'multinomial', solver='saga', class_weight = class_wt)\n",
    "lt_grid = {'penalty':['l1','l2'], 'C':list(np.arange(1, 10, 1))}\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb_grid = [{'alpha': np.arange(1,10,0.5)}]\n",
    "\n",
    "classifiers = [svm, dt,logit, knn]\n",
    "classifiers_p = ['svm', 'dt','logit', 'knn']\n",
    "dicts = [ svm_params, dt_grid, lt_grid, knn_grid]\n",
    "\n",
    "\n",
    "# Nested cross-validation\n",
    "for i in range(4):\n",
    "    print('Training:' , classifiers_p[i])\n",
    "    inner_cv = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "    outer_cv = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "    # Non_nested parameter search and scoring\n",
    "    clf = GridSearchCV(estimator=classifiers[i], param_grid=dicts[i], cv=inner_cv, iid=False, n_jobs = -1, scoring= scr, verbose = 0)\n",
    "    clf.fit(x_train, y_train)\n",
    "    non_nested_scores[i] = clf.best_score_\n",
    "\n",
    "    # Nested CV with parameter optimization\n",
    "    nested_score = cross_val_score(clf, X=x_train, y=y_train, cv=outer_cv)\n",
    "    nested_scores[i] = nested_score.mean()\n",
    "    \n",
    "print(nested_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From nested Gridsearch, SVM Provides the best accuracy for the model.  \n",
    "We perform further Hyperparameter Tunig to get the best parameters for SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: -187.41195652173914\n",
      "Best Parameters: {'C': 0.01, 'gamma': 0.001, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(class_weight=class_wt, random_state= 42)\n",
    "svm_params = [{'kernel': ['rbf'], 'gamma': [1e-2, 1e-3, 1e-4],'C': np.arange(0.01,3,0.5)},\n",
    "#               {'kernel': ['linear'], 'C': np.arange(0.01,3,0.5)},\n",
    "#               {'kernel': ['poly'], 'C': np.arange(0.01,3,0.5), 'degree': np.arange(1, 3, 1), 'coef0':np.arange(0,3,0.5)},\n",
    "              {'kernel':['sigmoid'], 'gamma': [1e-2, 1e-3, 1e-4], 'C': np.arange(0.01,3,0.5)}\n",
    "             ]\n",
    "\n",
    "classifier = GridSearchCV(svm, param_grid= svm_params, cv = 5, scoring = scr, n_jobs = -1, verbose = 0)\n",
    "classifier.fit(x_train, y_train)\n",
    "print(\"Best Score:\",classifier.best_score_)\n",
    "print(\"Best Parameters:\",classifier.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Score: -57.0\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(class_weight=class_wt, C = 0.01, gamma = 0.001, kernel = 'rbf')\n",
    "svm.fit(x_train, y_train)\n",
    "\n",
    "print('SVM Score:',scr(y_test, xg.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting Target Variable to Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train1 = to_categorical(y_train, num_classes=2)\n",
    "y_test1 = to_categorical(y_test, num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Basic Neural Network is used to Train the model. We use 3 hidden layers and an output layer to predict if an observation will be classified as a 1 or a zero.  \n",
    "Further, We use sigmoid as output function and categorical crossentropy to calculate the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(units = 10, activation = tf.nn.leaky_relu , input_shape=(57,)),\n",
    "        tf.keras.layers.Dense(units = 16, activation = tf.nn.leaky_relu),\n",
    "        tf.keras.layers.Dense(units = 16, activation = tf.nn.leaky_relu),\n",
    "        tf.keras.layers.Dense(units = 16, activation = tf.nn.leaky_relu),\n",
    "        tf.keras.layers.Dense(2, activation=\"sigmoid\")])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics = ['acc'])\n",
    "\n",
    "clf = model.fit(pd.DataFrame(x_train),\n",
    "                pd.DataFrame(y_train1),\n",
    "                batch_size= 10, epochs = 50, verbose = 0, validation_split= 0.2)\n",
    "\n",
    "loss_train, accuracy_train = model.evaluate(x_train, y_train1, verbose = False)\n",
    "loss, accuracy = model.evaluate(x_test, y_test1, verbose = False)\n",
    "print('loss_train:', loss_train, 'loss_test:', loss)\n",
    "print('accuracy_train:', accuracy_train, 'accuracy_test:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe ascore of -53 with Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   21.2s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   39.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   51.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 135, 'min_samples_split': 8, 'min_samples_leaf': 8, 'max_depth': 5, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(bootstrap=True, random_state= False, class_weight=class_wt)\n",
    "rf_grid = {\n",
    "    'n_estimators':range(5,200,10),\n",
    "    'criterion':['gini', 'entropy'],\n",
    "    'max_depth':range(3,20),\n",
    "    'min_samples_split':list(range(2,15)), \n",
    "    'min_samples_leaf':list(range(2,15))\n",
    "    }\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=rf_grid, n_iter=200, scoring=scr, \n",
    "                              cv=KFold(n_splits=5, shuffle=True, random_state=45), verbose=1, n_jobs=-1, random_state=45)\n",
    "rf_random.fit(x_train, y_train)\n",
    "print(rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: -62.0\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators =135, min_samples_split=8, min_samples_leaf = 8, max_depth= 5, criterion ='entropy')\n",
    "rf.fit(x_train, y_train)\n",
    "print('Score:',scr(y_test, rf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Baseline Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg=xgb.XGBClassifier(random_state = 42)\n",
    "xg_grid = {\n",
    "    'learning_rate':[0.1,0.05,0.01],\n",
    "    'n_estimators':range(5,200,10),\n",
    "    'max_depth':range(3,20),\n",
    "    'min_child_weight':range(1,6),\n",
    "    'gamma':[i/10.0 for i in range(0,5)],\n",
    "    'subsample':[i/10.0 for i in range(6,10)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,10)],\n",
    "    'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "    }\n",
    "\n",
    "xg_random = RandomizedSearchCV(estimator=xg, param_distributions=xg_grid, n_iter=100, scoring='accuracy', \n",
    "                              cv=KFold(n_splits=4, shuffle=True, random_state=45), verbose=0, n_jobs=-1, random_state=45)\n",
    "\n",
    "xg_random.fit(x_train, y_train)\n",
    "print(xg_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: -74.5\n"
     ]
    }
   ],
   "source": [
    "xg = xgb.XGBClassifier(subsample = 0.8, \n",
    "                       reg_alpha= 0.1, \n",
    "                       n_estimators= 175, \n",
    "                       min_child_weight=1, \n",
    "                       max_depth = 13, \n",
    "                       learning_rate = 0.1, \n",
    "                       gamma =0.4, \n",
    "                       colsample_bytree =0.8)\n",
    "print('Score:',np.mean(cross_val_score(xg, x_test, y_test, scoring = scr, cv = 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Above Parameters, We first Train the Model for Max Depth and Child Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: -166.40190217391304\n",
      "Best parameters: {'max_depth': 18, 'min_child_weight': 1}\n"
     ]
    }
   ],
   "source": [
    "# Grid Search for best parameters\n",
    "param_test = {'max_depth':list(range(10,20,2)), \n",
    "              'min_child_weight':list(range(1,8,2))}\n",
    "\n",
    "gsearch=GridSearchCV(estimator=xgb.XGBClassifier(subsample = 0.8, \n",
    "                                               reg_alpha= 0.1, \n",
    "                                               n_estimators= 175,\n",
    "                                               learning_rate = 0.1, \n",
    "                                               gamma =0.4, \n",
    "                                               colsample_bytree =0.8,\n",
    "                                                njobs=-1,\n",
    "                                                scale_pos_weight=1,\n",
    "                                                seed=123),\n",
    "                      param_grid=param_test,\n",
    "                      scoring=scr,\n",
    "                      n_jobs=-1,\n",
    "                      iid=True,\n",
    "                      cv=5, verbose=0)\n",
    "\n",
    "gsearch.fit(x_train, y_train)\n",
    "print(\"Best Score:\",gsearch.best_score_)\n",
    "print(\"Best parameters:\",gsearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We Then Use this to Set Learning Rate and number of estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: -158.80597826086955\n",
      "Best parameters: {'learning_rate': 0.05, 'n_estimators': 210}\n"
     ]
    }
   ],
   "source": [
    "# Grid Search for best parameters\n",
    "param_test = {'learning_rate':list(np.arange(0.05,1,0.05)), \n",
    "              'n_estimators':list(range(180,225,10))}\n",
    "\n",
    "gsearch=GridSearchCV(estimator=xgb.XGBClassifier(learning_rate=0.15,\n",
    "                                                n_estimators=100,\n",
    "                                                max_depth=18,\n",
    "                                                min_child_weight=1,\n",
    "                                                gamma=0,\n",
    "                                                subsample=0.9,\n",
    "                                                colsample_bytree=0.8,\n",
    "                                                njobs=-1,\n",
    "                                                scale_pos_weight=1,\n",
    "                                                seed=123),\n",
    "                      param_grid=param_test,\n",
    "                      scoring=scr,\n",
    "                      n_jobs=-1,\n",
    "                      iid=True,\n",
    "                      cv=5, verbose=0)\n",
    "\n",
    "gsearch.fit(x_train, y_train)\n",
    "print(\"Best Score:\",gsearch.best_score_)\n",
    "print(\"Best parameters:\",gsearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We use above obtained Results for Regularization Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  20 | elapsed:   13.5s remaining:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   13.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: -154.60434782608695\n",
      "Best parameters: {'reg_lambda': 2}\n"
     ]
    }
   ],
   "source": [
    "# Grid Search for best parameters\n",
    "param_test = {'reg_lambda':[0.1, 0.5,1,2]}\n",
    "\n",
    "gsearch=GridSearchCV(estimator=xgb.XGBClassifier(learning_rate=0.05,\n",
    "                                                n_estimators=210,\n",
    "                                                max_depth=18,\n",
    "                                                min_child_weight=1,\n",
    "                                                gamma=0,\n",
    "                                                subsample=0.9,\n",
    "                                                colsample_bytree=0.8,\n",
    "                                                njobs=-1,\n",
    "                                                scale_pos_weight=1,\n",
    "                                                seed=123),\n",
    "                      param_grid=param_test,\n",
    "                      scoring=scr,\n",
    "                      n_jobs=-1,\n",
    "                      iid=True,\n",
    "                      cv=5, verbose=1)\n",
    "\n",
    "gsearch.fit(x_train, y_train)\n",
    "print(\"Best Score:\",gsearch.best_score_)\n",
    "print(\"Best parameters:\",gsearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then We use the Learning Rate and estimatiors to again get best max_depth and child weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: -152.39864130434782\n",
      "Best parameters: {'max_depth': 16, 'min_child_weight': 1}\n"
     ]
    }
   ],
   "source": [
    "# Grid Search for best parameters\n",
    "param_test = {'max_depth':list(range(10,25,2)), \n",
    "              'min_child_weight':list(range(1,8,2))}\n",
    "\n",
    "gsearch=GridSearchCV(estimator=xgb.XGBClassifier(learning_rate=0.05,\n",
    "                                                n_estimators=210,\n",
    "                                                gamma=0,\n",
    "                                                subsample=0.9,\n",
    "                                                colsample_bytree=0.8,\n",
    "                                                njobs=-1,\n",
    "                                                scale_pos_weight=1,\n",
    "                                                seed=123,\n",
    "                                                reg_lambda = 2),\n",
    "                      param_grid=param_test,\n",
    "                      scoring=scr,\n",
    "                      n_jobs=-1,\n",
    "                      iid=True,\n",
    "                      cv=5, verbose=1)\n",
    "\n",
    "gsearch.fit(x_train, y_train)\n",
    "print(\"Best Score:\",gsearch.best_score_)\n",
    "print(\"Best parameters:\",gsearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: -74.5\n"
     ]
    }
   ],
   "source": [
    "xg = xgb.XGBClassifier(subsample = 0.8, \n",
    "                       reg_alpha= 0.1, \n",
    "                       n_estimators= 175, \n",
    "                       min_child_weight=1, \n",
    "                       max_depth = 13, \n",
    "                       learning_rate = 0.1, \n",
    "                       gamma =0.4, \n",
    "                       colsample_bytree =0.8)\n",
    "xg.fit(x_train, y_train)\n",
    "print('Score:',scr(y_test, xg.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Classifier | Accuracy |\n",
    "|--|--|\n",
    "|SVM|57|\n",
    "|Neural Network|53|\n",
    "|Random Forest|62|\n",
    "|XGBoost|74.7|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Final model obtained has a cost of SVM is able to give the best cost of 57 in this regard."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
